{"podcast_details": {"podcast_title": "The Stack Overflow Podcast", "episode_title": "Making event-driven development predictable with Discover", "episode_image": "https://image.simplecastcdn.com/images/f0fdf349-149b-42f9-95d0-8ddf72185776/02a60604-9d42-4ec4-a716-8d9a2942f79c/3000x3000/stack-overflow-podcast-1080x1080.jpg?aid=rss_feed", "episode_transcript": " Hello everybody, welcome back to the Stack Overflow podcast, a place to talk all things software and technology. I am your host Ben Popper, Director of Content here at Stack Overflow, joined as I often am by my colleague and collaborator, Ryan Donovan. Hey Ryan, how you doing? I'm good, Ben. How are you doing? Doing well, thanks. So today we have a sponsored podcast brought to us by the fine folks over at Discover. And we're going to be chatting with them about some of the tech that goes into things like payments and the way they approach developer experience and architecture. We're going to be talking about domain driven design, event driven architecture, Kafka streams, all those fun things that you can leverage when you're building interesting FinTech products, both from the customer experience as well as the experience of the folks on the inside who are building it. So today let's welcome our guests, Paul and Emanuele. Welcome to the Stack Overflow podcast. Both of you, hello. Hello, yeah, thank you. Good to be here. Thank you. So Paul, just really quickly, why don't you tell folks kind of who you are, what it is you do day to day and how would you define Discover, especially as it is in the UK where you are and maybe it's not quite as well known a brand. Yeah, cool. Yeah, so hello, I'm Paul Manning. I'm a Principal Application Engineer. I've worked in the payments industry now for nearly two decades and I've been with Discover in the UK for over three and a half years. So I work in the digital payments domain and I do everything from kind of delivering some of the business value stories, but also kind of working across some of our dev teams for some of those kind of like those bigger technical challenges, things like observability, tracing and then kind of just last week I was kind of doing a few internal presentations on chaos testing. So yeah, nice kind of mix of challenges and dev stuff. So Discover, yeah, so as you said, kind of in the US we're well known. So Discover Financial Services, we're a digital banking and payment services company, one of the most kind of recognized brands within the US. We're one of the largest card issuers in the US. We just issue the Discover card and then the banking side of business does kind of student personal home loans, checking savings accounts, etc. And then we offer, we operate even the Discover global network. So there's millions of merchants and cash access locations, Pulse, which is a leading ATM debit network. And we've got Diners International, which is a huge global payments network with acceptance all around the world. And then, as I mentioned, I'm based in the UK. So here we've got a really strong engineering presence here. So although we're relatively smaller in terms of number of people, we're highly thought of. We've got our own kind of hub in Farnborough in Hampshire, where we're kind of seen as a unit in our own right with kind of our own identity. And then, you know, working with the technical teams, we've got a really strong approach to upskilling our engineering workforce through collaboration, innovation, learning. We form some really good internal communities to help build our craft, improve our products and grow as engineers. So we place a great emphasis on engineering talent. So it's a great place to work. Terrific. Emmanuel, would you like to give folks just a quick background, sort of who you are and what you specialize in? Yes. Okay. My name is Emmanuel Pugliese and I've been working at Discover for about seven years. I work as an architect for the digital payment platform. And basically, our mission is to enable all the cardholders to be able to make payments using their mobile devices and their apps. And this is our area, core area. In addition to what Paul has said, I would add that Discover gives the opportunity of working in different departments and learning a lot about the payment ecosystem. I started as a senior engineer on our data integration pipeline using data, big data and technologies such as Spark and HBase. And after that, I worked on the tech lead on the dispute platform, mainly working on microservices and RabbitMQ. And finally, on the digital payment platform using Kubernetes, Docker and Kafka. Therefore, I want to say that for engineers working at Discover, we have got an amazing opportunity in using relevant technology and as well as growing in our career. Very cool. So obviously, Discover is a big player in the payment space. So what's the tech behind a global payment network like this? So within the payment space, we're doing a whole load of cloud native containerized microservices, Java, Spring, Spring Boot. We mix SQL and NoSQL data stores and we kind of leverage a mixture of event driven and RESTful APIs. So it's a really nice kind of modern tech stack with a big, big emphasis, high importance on security, resilience, those kinds of things. And it's also kind of worth adding that we've got a big emphasis for our teams for kind of you build it, you run it. So where, you know, ad dev teams, they're all empowered to come up with solutions, new technologies and kind of ways of working that really kind of enable us to be the best that we can. Awesome. And Emanuele, I know out of that tech stack, you know, you focused a bit on event driven architecture. Can you define for folks what that is and then maybe talk a little bit about how that's applied at Discover? Yes, basically at Discover, we use event driven architecture and we combine it with Kafka stream and domain driven design as well. We think that these architectural patterns really complement each other. And to understand why, I would like to maybe to start speaking about orchestration and the choreography and compare these two design patterns. In case of orchestration, this is often used with asynchronous REST APIs to target specific backend services that are responsible for both processing the request and processing the response. In case of event in choreography, the backend services that process the request may be different from the backend service that are processing the response. This is a very key point that allows us to add multiple services and business capabilities over time and those new capabilities can be run in parallel or contribute to the final response of our original request. Therefore this becomes a flexible mechanism for evolving our design and the scaling services in different ways. Shall I go with an example? Yeah, an example would be great. Let's assume we have a client that wants to enable a card holder or card holders to add their payments card on their mobile wallets. Then we decide to create an edge service to interface with the client. And then we create a card eligibility backend service to verify if the card is eligible to be added to the wallet. And finally another service that is the virtual card service to create a virtual card. The virtual card is then added to the wallet in place of the actual payment card for security reasons. To be able to orchestrate the two backend services, we decide to create a central orchestration service. And this is okay until we get a new client that has got slightly different requirements. Now we decide to, for example, change one of the APIs like the card eligibility APIs. And then soon after other 10 clients are coming in with slightly different requirements. And suddenly we have got a tower orchestrator that has become very complex and difficult to maintain. And the advice here is if we are dealing with multiple clients and the clients have different requirements, we should avoid creating a central orchestrator. To solve this problem, we can use, for example, events and choreography. And in this case, we could assign the card eligibility service to emit a card eligibility provided event that the virtual card service can listen to. If the card is eligible, then the virtual card is added to the wallet. Then, you know, there is no need of a central orchestrator anymore. And at this point, the Edge service can use a request response, the same pattern, to correlate the different topics. Again, we need to bear in mind that the two topics have been populated by different backend services in this case. And the request response is a valuable pattern. But there is an even better pattern in many scenarios. It is Kafka Stream. Because events are stored in Kafka, each topic can be seen as a stream or table of events. Therefore, Kafka Stream library can perform a join and aggregates, aggregation operation directly on topics alongside other operations. And in simple use case scenario, we don't need that to even maintain a data store or a database. Kafka Stream can do it for us. And this is why potentially Kafka Stream and events-driven are sort of Lego blocks that allows you to build a better the couple architecture. Because you can plug in all these services in the middle and, you know, design them appropriately. That's the example, basically. Yeah, so I think one of the things Ryan and I love to do, you know, when we're talking to folks is a little bit about the pros and cons, right, Ryan? Yes, I think, yeah, Emanuele mentioned some of those benefits. But I mean, one thing that kind of struck struck me is when we kind of, you know, we do a proof of concept, and that's quite easy to get, you know, there's so many tutorials and walkthroughs out there, you kind of get those working. Once you've kind of, you know, you've high fived each other, you've got somebody working. Then when you try and scale it out, you start to kind of spot those those pain points that you need to kind of think of sooner rather than later, because they're only going to hurt the further you kind of kick that can down the road. And something like like sharing a schema between a producer and a consumer, you know, it can seem quite straightforward to start off with. But once you start to scale that to tens and hundreds of consumers, that's a whole whole different problem. So if you've got a producing team wanting to change a schema, communicating that change out to those other teams can be really difficult. So some kind of like central point source of truth to retrieve that schema is needed. And then you kind of need to think, well, how's that going to evolve over time? Everything's about evolving architecture. So how's that evolve over time? And depending on how compatible your changes that could influence how you have to upgrade your producers or your consumers, which ones go first. And then finally, don't forget, if you're if you're replaying old events, you can still need that old schema, you know, way after if you're replaying events to reconstruct some form of state. And then finally, you've got to think how does all that get through test to production? How is it rolled back if it goes wrong? You know, with the CICD mindset, you want those producers and consumers to be able to release at any point. So getting all that testing is vital and getting that contract testing, much like in a kind of a restful world with between your server and clients is important as well. Yeah. So you talked about replaying and making sure you get the data. But what about like, you know, when you retry actual events, you don't want to charge people twice. Right. So how do you go about doing reliable retries? Yeah, that's an interesting one. And it's a very difficult, different world from kind of the restful response, because once those events are on your on your queue, your topic, your partition, the onus is on the on the consumer to handle those retries. So so we kind of looked from like, there's two different types that to me that stood out this kind of like a blocking retry, whereby you're you go around and you try and be processed that event. But you've got to be fully aware that that no other events are going to be produced are going to be consumed on that thread until you've sorted that. So so that comes with pros and cons. The other the other way we kind of looked at it was you've got kind of no blocking asynchronous type retries. So you put it onto a different a different topic straight away. And then you can kind of take some time over that you can have exponential backups, you can have max attempts at retries. And maybe you even have to produce that to a series of retry topics. I mean, ultimately, there always becomes a point whereby you've got to put it onto some kind of dead letter topic, dead letter queue, and maybe some form of manual intervention is needed there to to kind of correct it and replay it if necessary. And you can also look at the type of exception that caused that event. So you know, something that might be retryable is maybe like a transient like network glitch. Yeah, you get those, you know, but you can quite quickly that that might fix itself. And you can go and straight away replay that and others are just inherently more complex. It's a lot easier with idempotent events as well. I'd say that's a massive thing. The more the more idempotent you can make things definitely easier. And then kind of finally, you've got to kind of design all that in mind. But it comes with quite an additional cognitive load on the developer to understand if you are complex retrying strategy. And also then, don't forget, you've got to have the observability, the monitoring, the alerting tools in place and test it as well because there's nothing you don't want to find out at three o'clock in the morning that something's gone wrong in production. And then find your observability, your monitoring tools aren't up to scratch. So we found something like game days, for example, where you get everybody together. And for us, that's UK, US, you get everyone in a virtual room, and you play through some of those scenarios. And that's a great way of like bringing those teams together, you know, and having having a look. It's great for fostering collaboration as well. So it's great. Yeah, that's interesting. Ryan and I were on a call earlier today about all about SRE. And you know, trying to install a culture where if folks build it, you know, they should know that at some point, they're going to be have to be the ones on call. And so when they're building it, you know, get into that mindset of reliability from the very beginning. And I think to your point, also, you know, having these group activities where everybody gets to participate in that to understand, you know, where some of the responsibility lies can kind of build that culture of understanding, well, I can't just, you know, create this chuck it over the wall and it's somebody else in operations, you know, problem that right, like we all have to maintain responsibility and sort of as a team for this. Yeah. And I would like to add also that maybe from the same pattern point of view, we could decide to implement, you know, I deport and see as Paul was saying, but also the outbox pattern would be a very good way of avoiding the processing of the same request multiple times. But going back to Kafka stream that allows us so it's properly implemented to use exactly one semantic, which means that we can prevent data loss and duplication, which really sits well on this use case scenario. There is different advantages. Like you know, you reduce also the code footprint, but you know, more importantly, exactly one semantic is something very difficult to achieve that can be achieved with Kafka stream. So we talked about the streams, but the other part of what we're y'all brought to this was about domain driven design. Can you talk about maybe how that fits into it and if you have any sort of best practice tips for other people trying to approach domain driven design? Yes, we design our system reflecting the business domain requirements and what are the aggregates and the microservices backing up those aggregates. And then what is really important once you have done that work is to be able also to document the design and the decision that have been made, the current architecture and the target architecture. And I found personally very difficult initially to understand how that could be done. And I've got a few tips on that. If you are trying to document the decision being made, there is the architectural decision on the record template ADR. This is a template you can find online and it is about documenting the problem statement, consider the options and the final decision that have been made. And on top of that, we want to document also the domain or sub domain. This require kind of a dedicated documentation that is more static. You can use the C4 model. This is another template you can find online and it is about documenting the context around your domain, the containers, components and potentially optionally the code as well. And finally, once you have got all this documented, each incremental value initiative or project will require also an end-to-end documentation where you bring together all those sub domains and you provide clarity around the design and how this is impacting your system. And these are the major tips I would have for documenting DDD. Paul, how about you? Do you have like, does this come up in your actual work or with you and engineers and teams you work with? From the DDD perspective, what would you say has been important and valuable? I would go ADRs. Again, I'd reiterate what Emanuele just said about ADRs. I think they're absolutely brilliant. I mean, literally just like a couple of weeks ago, I had someone who was talking to me and it reminded me of some work that I did like about a year ago with some performance testing. And it was great that I knew exactly where that was. It's in the code. Yeah, I could give them the GitHub link and it's got everything, all the challenges that I faced at the time, the rationale around some of the decisions that were made. And yeah, I could send that over and it's literally like a snapshot in time. Brilliant. Use them. So we've chatted a little bit about sort of the benefits of DDD, EDA and Kafka Streams. Are there challenges or cons associated with this as well? People are considering this as maybe setting up the core of their next payment startup or inside of their business. What should they consider? Yes, it is very important for architects to have engagement with all the stakeholders, including the business. We think like the business, the one providing requirements and knowing everything about what is needed to be done, but in reality, it's a collaboration effort. It is about discovering what the current solution does, what are the client's requirements and come with a domain model. And there are different ways of doing that, but like event storming and gathering everybody in one room and discussing about those requirements and systems. But that is challenging as well. You found out that there are a lot of unknowns, a lot of ideas, and this is where I think what's mentioned in documentation is important. We start putting down all those ideas, documenting the decision and aggregating the solution using the documentation types I mentioned. I think that was one of the main challenges. Another challenge is that actually we need to think about the system as a system that keeps evolving. And this is why it is important to be able not to have a design upfront, but break down the solution in a way that is scalable. And again, this is where I think event-driven really helps by being able to plug a new capability using the existing topics and events you have in the system. And yes, mainly it's a challenging architectural pattern in the AI. It is not complex compared to having an orchestrator managing the state. But at the same time, it allows you to, if properly done, to create generic events. Those events are reflecting the business domain and you can leverage those events from different applications. So that brings up an interesting point. So how do you actually scale an event-driven architecture? With normal service stuff, you just spawn more instances, more containers. Is there something else you have to do with event-driven architecture? This brings to the challenge of how you can scale Kafka. And there are different ways. For example, you can link clusters. But mainly it is important to understand that scalability using Kafka, it is connected to the number of partitions. And being able to create the right number of partitions is important. And also running the performance test against a production-like environment is essential. There is no solution out of the box there. It's all about trying your business service, test it, see how it reacts, and then understanding the batching strategy, the fin-tuning. Kafka is really essential there. And we cannot, in most cases, aim to infinite scalability. But instead we should aim to understand our requirements first and try to achieve those. Yeah I think that's a really important point you make. So Paul, I know this wasn't part of the script that we had prepared, but that's why we do chaos testing, right? So you were talking before we set the mics live about how you've been working on some of that with your team. Ryan and I love this topic. We've gone over it with folks from AWS, Netflix, a bunch of other places. How have you been doing chaos testing internally and what are you seeing as some of the benefits there? What cracks is it maybe exposing that you are going to want to address in the future? And how does it bring your team together? Yeah so it's interesting. I've only just got into it over the past few years. It was almost on the side. Yeah, as you see it, it feels like it's becoming more and more important. Discover resiliency and that all the operational aspects are vital. So chaos testing perfectly feeds into that. And when you're running in kind of cloud native world, you've got all those little network glitches coming up and going down, all those kinds of things. So I've really enjoyed getting in there, putting through, you can add in like little proxies here and there to add in, simulate some latency. And then you throw in some performance testing on that. And then you see kind of how does that look? And then you kind of contest your, get your dev teams in the room and say, okay, cool. How's the operational and the monitoring side looking with all this additional latency going on? That's kind of what the problem is. We haven't done it yet, but one of my plans to do is to actually have a malicious actor in the room who's there, tearing down pods, killing off partitions, taking nodes down, that sort of stuff. Let's see how evil they could be and how quickly you can identify and get over those problems. That's right. Have somebody in the room engineering the chaos for you. Yeah, yeah. An evil person. That sounds good. I like the sound of it. No, it is also very important to start doing and thinking about the test case, chaos at the start of your project. Even if you go live with a very rudimental service, still you can test the disaster recovery strategy. You can still try to bring down the network, bring down the pod and see what is happening to your system. Then it is really helping engineers to get accustomed to the idea that application network and the cluster can go down and start thinking on how we can address those issues. Then failure of strategies, active-active-active passive configuration. And it is a fundamental tool that we should make use of as soon as possible. Very cool. All right, everybody. Thanks again for listening. I am Ben Popper, Director of Content here at Stack Overflow. You can always find me on Twitter or X as it's now called. You can find me on X at Ben Popper. You can email us with questions or suggestions about the podcast, Podcast at Stack Overflow. If you like the show, do me a favor, leave us a rating and a review. It really helps. I am Ryan Donovan. I edit the blog here at Stack Overflow. You can find it at stackoverflow.blog and you can reach out to me on the former Bird site at RRThor Donovan. I am Paul Manning. You can reach me on LinkedIn. And also, if you get a chance, check out jobs.discover.com. I am Emanuele Pugliese. I am an architect at Discover Financial Services. Yeah, all right. And we'll make sure to put the link in the show notes. Thanks for listening everybody. And we will talk to you soon."}, "podcast_summary": "In this episode of the Stack Overflow podcast titled \"Payments, Developer Experience, and Architecture at Discover,\" the host, Ben Popper, and his colleague, Ryan Donovan, chat with Paul Manning and Emanuele Pugliese from Discover about the tech behind a global payment network, including event-driven architecture and Kafka streams. They discuss the benefits and challenges of domain-driven design, scalability considerations, and the importance of chaos testing. They also touch on the use of architectural decision records and documentation in the development process.", "podcast_guest": "Not Available", "podcast_highlights": "Timestamp (00:00:00) - Introduction and welcome\nTimestamp (00:02:18) - Introduction to Discover and its role in the UK\nTimestamp (00:03:51) - Introduction to Paul Manning, Principal Application Engineer at Discover\nTimestamp (00:08:10) - Introduction to Emanuele Pugliese, architect for the digital payment platform at Discover\nTimestamp (00:14:03) - Tech behind a global payment network like Discover\nTimestamp (00:17:21) - Event-driven architecture and its application at Discover\nTimestamp (00:22:23) - Challenges and considerations for event-driven architecture\nTimestamp (00:27:02) - Reliable retries in event-driven architecture\nTimestamp (00:31:15) - Scaling event-driven architecture and considerations for scaling Kafka\nTimestamp (00:34:57) - Domain-driven design (DDD) and its role in architecture\nTimestamp (00:39:17) - Challenges and benefits of DDD in practice\nTimestamp (00:43:25) - Chaos testing and its importance for resiliency and operational aspects\nTimestamp (00:46:20) - Closing remarks and contact information"}